{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2 - Word Generator/ Predictor",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcCD15vhHGbQ"
      },
      "source": [
        "Let's import all the libraries and classes we will need while making this project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.regularizers import Regularizer\n",
        "\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKAs7efCNDId"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXROh8GuHWeg"
      },
      "source": [
        "Now we will read the data. I'm reading the data from my github profile link, you can directly use txt files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3oel-VxFsaK"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/ishantjuyal/Word-Prediction/master/Lyrics%20by%20Artists/Kanye_West.txt\"\n",
        "data = urllib.request.urlopen(url).read().decode(\"utf-8\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9MCosIcIH0n"
      },
      "source": [
        "Now we will convert data, which is a string to a list containing differrent sentences. \n",
        "As we can see, in the string, \"end of line\" is represented by \"\\r\\n\". So, we will split the string by \"\\r\\n\" and store them as list in corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvlyWKMRKNsy"
      },
      "source": [
        "# Splitting the string into sentences, while converting whole data into lowercase. \n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "# Now, to make sure no sentence appears twice in our corpus, we use set. Otherwise, it will make the model biased.\n",
        "corpus = list(set(corpus))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U5dGCoYa9Gn"
      },
      "source": [
        "for i in range(len(corpus)):\n",
        "    sentence = corpus[i]\n",
        "    sentence = \"startsentence \" + sentence + \" endsentence\"\n",
        "    corpus[i] = sentence"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztz9xk_LMlDb"
      },
      "source": [
        "Let's see how an element of corpus looks like. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwQMFmCIMiFY",
        "outputId": "97cbebae-8fa2-4544-f599-0cf8e34c53e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "corpus[3]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'startsentence well whos maybach is this mr wests endsentence'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XusOCWiyMrIb"
      },
      "source": [
        "As we can see, it is just a sentence without any \"\\r or \\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSuoyJVGI6D5"
      },
      "source": [
        "# Organising Data\n",
        "Now we will use Tokenizer to convert the words to word vectors. \n",
        "Our model understands numbers only, so we need to give it numbers instead of words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-X6EuigK0AW",
        "outputId": "8a578567-1335-427d-a4ac-40da89d139eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Input Sequences\")\n",
        "print(input_sequences)\n",
        "print(\"*****\")\n",
        "print(\"Shape of Input Sequences\", input_sequences.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sequences\n",
            "[[   0    0    0 ...    0    1    2]\n",
            " [   0    0    0 ...    0    1 1331]\n",
            " [   0    0    0 ...    1 1331  245]\n",
            " ...\n",
            " [   0    0    0 ...  442   33 6143]\n",
            " [   0    0    0 ...   33 6143 1028]\n",
            " [   0    0    0 ... 6143 1028    2]]\n",
            "*****\n",
            "Shape of Input Sequences (56557, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EuezRa8KNYC",
        "outputId": "198d73c6-081f-46f0-92ee-54beb7528259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Predictors\")\n",
        "print(predictors)\n",
        "print('*****')\n",
        "print(\"Shape of predictors is\", predictors.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictors\n",
            "[[   0    0    0 ...    0    0    1]\n",
            " [   0    0    0 ...    0    0    1]\n",
            " [   0    0    0 ...    0    1 1331]\n",
            " ...\n",
            " [   0    0    0 ...    6  442   33]\n",
            " [   0    0    0 ...  442   33 6143]\n",
            " [   0    0    0 ...   33 6143 1028]]\n",
            "*****\n",
            "Shape of predictors is (56557, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXv6R3EwbZEt",
        "outputId": "5a45ca29-3601-49a5-e01e-54e3190b289c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Label\")\n",
        "print(label)\n",
        "print(\"*****\")\n",
        "print(\"Shape of label\", label.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "*****\n",
            "Shape of label (56557, 6144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SyLUtByJ2WK"
      },
      "source": [
        "Now, we will start building model using Keras. We use LSTM so that our model could be more accurate and understand the context better. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "outputId": "d1b04574-3832-4975-b87e-53f921690d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 50, input_length=max_sequence_len-1))  #(# Embedding Layer)\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))  #(An LSTM Layer)\n",
        "model.add(Dropout(0.2))  #(# A dropout layer for regularisation)\n",
        "model.add(LSTM(100))  #(# Another LSTM Layer)\n",
        "model.add(Dense(total_words/2, activation='relu'))  #(# A Dense Layer including regularizers)\n",
        "#(# Last Layer, the shape is equal to total number of words present in our vocabulary)\n",
        "model.add(Dense(total_words, activation='softmax'))  \n",
        "# Pick an optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
        "print(model.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 50)            307200    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 20, 300)           241200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3072)              310272    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6144)              18880512  \n",
            "=================================================================\n",
            "Total params: 19,899,584\n",
            "Trainable params: 19,899,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "outputId": "ba8fdc61-5245-4bb8-df8b-be3f0cb9b9f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(predictors, label, epochs= 120, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 6.2006 - accuracy: 0.1070\n",
            "Epoch 2/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 5.7905 - accuracy: 0.1236\n",
            "Epoch 3/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 5.5255 - accuracy: 0.1476\n",
            "Epoch 4/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 5.3314 - accuracy: 0.1558\n",
            "Epoch 5/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 5.1848 - accuracy: 0.1619\n",
            "Epoch 6/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 5.0565 - accuracy: 0.1661\n",
            "Epoch 7/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 4.9306 - accuracy: 0.1726\n",
            "Epoch 8/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 4.8028 - accuracy: 0.1784\n",
            "Epoch 9/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 4.6797 - accuracy: 0.1854\n",
            "Epoch 10/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 4.5575 - accuracy: 0.1906\n",
            "Epoch 11/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 4.4351 - accuracy: 0.1956\n",
            "Epoch 12/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 4.3148 - accuracy: 0.2017\n",
            "Epoch 13/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 4.1917 - accuracy: 0.2078\n",
            "Epoch 14/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 4.0705 - accuracy: 0.2156\n",
            "Epoch 15/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.9502 - accuracy: 0.2224\n",
            "Epoch 16/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.8315 - accuracy: 0.2309\n",
            "Epoch 17/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.7107 - accuracy: 0.2411\n",
            "Epoch 18/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.5922 - accuracy: 0.2521\n",
            "Epoch 19/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.4809 - accuracy: 0.2649\n",
            "Epoch 20/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.3651 - accuracy: 0.2788\n",
            "Epoch 21/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 3.2562 - accuracy: 0.2943\n",
            "Epoch 22/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 3.1514 - accuracy: 0.3086\n",
            "Epoch 23/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 3.0602 - accuracy: 0.3203\n",
            "Epoch 24/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 2.9549 - accuracy: 0.3408\n",
            "Epoch 25/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 2.8694 - accuracy: 0.3528\n",
            "Epoch 26/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.7837 - accuracy: 0.3685\n",
            "Epoch 27/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.7066 - accuracy: 0.3808\n",
            "Epoch 28/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 2.6239 - accuracy: 0.3981\n",
            "Epoch 29/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 2.5512 - accuracy: 0.4109\n",
            "Epoch 30/120\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 2.4732 - accuracy: 0.4247\n",
            "Epoch 31/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.4091 - accuracy: 0.4350\n",
            "Epoch 32/120\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 2.3488 - accuracy: 0.4485\n",
            "Epoch 33/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.2847 - accuracy: 0.4640\n",
            "Epoch 34/120\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 2.2235 - accuracy: 0.4742\n",
            "Epoch 35/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.1674 - accuracy: 0.4885\n",
            "Epoch 36/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 2.1166 - accuracy: 0.4980\n",
            "Epoch 37/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.0701 - accuracy: 0.5080\n",
            "Epoch 38/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 2.0177 - accuracy: 0.5226\n",
            "Epoch 39/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.9717 - accuracy: 0.5323\n",
            "Epoch 40/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.9301 - accuracy: 0.5404\n",
            "Epoch 41/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.8894 - accuracy: 0.5508\n",
            "Epoch 42/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.8502 - accuracy: 0.5596\n",
            "Epoch 43/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.8113 - accuracy: 0.5694\n",
            "Epoch 44/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.7821 - accuracy: 0.5755\n",
            "Epoch 45/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.7418 - accuracy: 0.5861\n",
            "Epoch 46/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.7207 - accuracy: 0.5881\n",
            "Epoch 47/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.6985 - accuracy: 0.5961\n",
            "Epoch 48/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.6594 - accuracy: 0.6057\n",
            "Epoch 49/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.6385 - accuracy: 0.6102\n",
            "Epoch 50/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.6125 - accuracy: 0.6170\n",
            "Epoch 51/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.5959 - accuracy: 0.6219\n",
            "Epoch 52/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.5634 - accuracy: 0.6284\n",
            "Epoch 53/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.5537 - accuracy: 0.6319\n",
            "Epoch 54/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.5260 - accuracy: 0.6389\n",
            "Epoch 55/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.5139 - accuracy: 0.6391\n",
            "Epoch 56/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.4928 - accuracy: 0.6466\n",
            "Epoch 57/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.4757 - accuracy: 0.6512\n",
            "Epoch 58/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.4663 - accuracy: 0.6532\n",
            "Epoch 59/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.4545 - accuracy: 0.6566\n",
            "Epoch 60/120\n",
            "1768/1768 [==============================] - 29s 16ms/step - loss: 1.4347 - accuracy: 0.6619\n",
            "Epoch 61/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.4297 - accuracy: 0.6633\n",
            "Epoch 62/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.4170 - accuracy: 0.6667\n",
            "Epoch 63/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3957 - accuracy: 0.6708\n",
            "Epoch 64/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3942 - accuracy: 0.6719\n",
            "Epoch 65/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3801 - accuracy: 0.6754\n",
            "Epoch 66/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3709 - accuracy: 0.6778\n",
            "Epoch 67/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3624 - accuracy: 0.6804\n",
            "Epoch 68/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3541 - accuracy: 0.6820\n",
            "Epoch 69/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3425 - accuracy: 0.6842\n",
            "Epoch 70/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3293 - accuracy: 0.6881\n",
            "Epoch 71/120\n",
            "1768/1768 [==============================] - 29s 16ms/step - loss: 1.3315 - accuracy: 0.6866\n",
            "Epoch 72/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.3209 - accuracy: 0.6905\n",
            "Epoch 73/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3102 - accuracy: 0.6942\n",
            "Epoch 74/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.3059 - accuracy: 0.6953\n",
            "Epoch 75/120\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.2919 - accuracy: 0.6973\n",
            "Epoch 76/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2899 - accuracy: 0.6979\n",
            "Epoch 77/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2882 - accuracy: 0.6989\n",
            "Epoch 78/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.2768 - accuracy: 0.7005\n",
            "Epoch 79/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2732 - accuracy: 0.7024\n",
            "Epoch 80/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2681 - accuracy: 0.7029\n",
            "Epoch 81/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2582 - accuracy: 0.7062\n",
            "Epoch 82/120\n",
            "1768/1768 [==============================] - 29s 16ms/step - loss: 1.2559 - accuracy: 0.7071\n",
            "Epoch 83/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2624 - accuracy: 0.7051\n",
            "Epoch 84/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.2580 - accuracy: 0.7065\n",
            "Epoch 85/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.2389 - accuracy: 0.7120\n",
            "Epoch 86/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2455 - accuracy: 0.7108\n",
            "Epoch 87/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2481 - accuracy: 0.7101\n",
            "Epoch 88/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2300 - accuracy: 0.7125\n",
            "Epoch 89/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2307 - accuracy: 0.7137\n",
            "Epoch 90/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2212 - accuracy: 0.7177\n",
            "Epoch 91/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2196 - accuracy: 0.7171\n",
            "Epoch 92/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2197 - accuracy: 0.7159\n",
            "Epoch 93/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2180 - accuracy: 0.7157\n",
            "Epoch 94/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2109 - accuracy: 0.7206\n",
            "Epoch 95/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2055 - accuracy: 0.7207\n",
            "Epoch 96/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2080 - accuracy: 0.7186\n",
            "Epoch 97/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2001 - accuracy: 0.7217\n",
            "Epoch 98/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1995 - accuracy: 0.7215\n",
            "Epoch 99/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.2062 - accuracy: 0.7208\n",
            "Epoch 100/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1962 - accuracy: 0.7222\n",
            "Epoch 101/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1918 - accuracy: 0.7226\n",
            "Epoch 102/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1910 - accuracy: 0.7235\n",
            "Epoch 103/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1876 - accuracy: 0.7245\n",
            "Epoch 104/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1859 - accuracy: 0.7256\n",
            "Epoch 105/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1858 - accuracy: 0.7247\n",
            "Epoch 106/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1831 - accuracy: 0.7248\n",
            "Epoch 107/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1721 - accuracy: 0.7283\n",
            "Epoch 108/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1760 - accuracy: 0.7269\n",
            "Epoch 109/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1826 - accuracy: 0.7271\n",
            "Epoch 110/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1718 - accuracy: 0.7284\n",
            "Epoch 111/120\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1780 - accuracy: 0.7262\n",
            "Epoch 112/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1700 - accuracy: 0.7284\n",
            "Epoch 113/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1654 - accuracy: 0.7311\n",
            "Epoch 114/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1615 - accuracy: 0.7307\n",
            "Epoch 115/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1680 - accuracy: 0.7295\n",
            "Epoch 116/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1624 - accuracy: 0.7313\n",
            "Epoch 117/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1629 - accuracy: 0.7301\n",
            "Epoch 118/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1641 - accuracy: 0.7302\n",
            "Epoch 119/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1568 - accuracy: 0.7314\n",
            "Epoch 120/120\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1509 - accuracy: 0.7324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blUBajLlOPyD"
      },
      "source": [
        "Now, we will see how our model performed with each iteration. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWTK8pcgsmqG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graph(history,string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srDqi-U3smqW",
        "outputId": "a792e913-1de8-4bfa-ec3d-f41c0737abe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_graph(history,'accuracy')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70XUUhDnTpuY",
        "outputId": "14d409c2-a76d-4139-da3b-10a01c9b98c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_graph(history,'loss')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3n3gF-wotgL",
        "outputId": "5253211f-8660-44b7-b4d0-9222f1d7a92c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Further training if not satisfied\n",
        "history = model.fit(predictors, label, epochs= 30, verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1631 - accuracy: 0.7320\n",
            "Epoch 2/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1510 - accuracy: 0.7320\n",
            "Epoch 3/30\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1527 - accuracy: 0.7335\n",
            "Epoch 4/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1466 - accuracy: 0.7339\n",
            "Epoch 5/30\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1559 - accuracy: 0.7328\n",
            "Epoch 6/30\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1426 - accuracy: 0.7356\n",
            "Epoch 7/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1486 - accuracy: 0.7345\n",
            "Epoch 8/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1427 - accuracy: 0.7363\n",
            "Epoch 9/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1511 - accuracy: 0.7329\n",
            "Epoch 10/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1420 - accuracy: 0.7360\n",
            "Epoch 11/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1384 - accuracy: 0.7368\n",
            "Epoch 12/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1407 - accuracy: 0.7376\n",
            "Epoch 13/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1436 - accuracy: 0.7351\n",
            "Epoch 14/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1387 - accuracy: 0.7373\n",
            "Epoch 15/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1384 - accuracy: 0.7370\n",
            "Epoch 16/30\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1438 - accuracy: 0.7355\n",
            "Epoch 17/30\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1333 - accuracy: 0.7390\n",
            "Epoch 18/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1335 - accuracy: 0.7382\n",
            "Epoch 19/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1434 - accuracy: 0.7369\n",
            "Epoch 20/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1298 - accuracy: 0.7391\n",
            "Epoch 21/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1294 - accuracy: 0.7386\n",
            "Epoch 22/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1361 - accuracy: 0.7359\n",
            "Epoch 23/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1291 - accuracy: 0.7385\n",
            "Epoch 24/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1330 - accuracy: 0.7371\n",
            "Epoch 25/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1293 - accuracy: 0.7385\n",
            "Epoch 26/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1210 - accuracy: 0.7416\n",
            "Epoch 27/30\n",
            "1768/1768 [==============================] - 27s 16ms/step - loss: 1.1315 - accuracy: 0.7376\n",
            "Epoch 28/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1274 - accuracy: 0.7395\n",
            "Epoch 29/30\n",
            "1768/1768 [==============================] - 28s 16ms/step - loss: 1.1252 - accuracy: 0.7398\n",
            "Epoch 30/30\n",
            "1768/1768 [==============================] - 27s 15ms/step - loss: 1.1207 - accuracy: 0.7411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B528MBF2i36c"
      },
      "source": [
        "# How to save your trained model\n",
        "\n",
        "# serialize to JSON\n",
        "json_file = model.to_json()\n",
        "with open(\"model.json\", \"w\") as file:\n",
        "   file.write(json_file)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVdOEp1bjHzI"
      },
      "source": [
        "# How to load your saved model\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "file = open('model.json', 'r')\n",
        "model_json = file.read()\n",
        "file.close()\n",
        "loaded_model = model_from_json(model_json)\n",
        "# load weights\n",
        "loaded_model.load_weights(\"model.h5\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHaZnz8xpzY2"
      },
      "source": [
        "# Generate Lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6L4WV_lsmq2"
      },
      "source": [
        "def make_lyrics(seed_text):\n",
        "    ans = True\n",
        "    seed_text = \"startsentence \" + seed_text \n",
        "    while True:\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis = -1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        if output_word == \"endsentence\":\n",
        "            new_sentence_words = seed_text.split()[1:]\n",
        "            seed_text = ' '.join(new_sentence_words)\n",
        "            print(seed_text)\n",
        "            ans = False\n",
        "            break\n",
        "        seed_text += \" \" + output_word\n",
        "    if ans == True:\n",
        "        new_sentence_words = seed_text.split()[1:]\n",
        "        seed_text = ' '.join(new_sentence_words)\n",
        "        print(seed_text)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOkUwwAOKDJy",
        "outputId": "214c195d-0c33-4358-84fb-5a3750f665e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"How\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How you gon lie to the lawyer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsb9RquVOdo8",
        "outputId": "81122b36-8eeb-4dd7-a5fe-e83c29974606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"When I will\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When I will make it to the other side of sanity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9St39_AOmKM",
        "outputId": "ea053cda-7646-4c3d-f727-be4a42a13d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"Light in the\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Light in the morning you gon make it too soon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RveFcd0hOvVr",
        "outputId": "25408931-4deb-4147-e605-27261256bf49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"Walking\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Walking down melrose spot where they sell clothes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySdhR0oxO4GM",
        "outputId": "b3e31729-6766-4711-c116-7c9119cba94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"Do you\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Do you mind if i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y_T3Ujvg3cX",
        "outputId": "4d1c1d99-bea6-4d7a-f96b-c6ee934d3aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"Why would\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why would i mention your favorite song and you twerk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZaSp493s7Ll",
        "outputId": "5f2d61f5-76b2-4ad6-afa5-215b67e27139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"She\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She said you left your kids and they just like you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFz5ZxJ9x9vB",
        "outputId": "5cf41c3f-b395-4198-a9d1-eb6cd3a4bc30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"And all my people\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And all my people bitch black\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3fQaM-G0GCA",
        "outputId": "aeb8ee53-2856-4d68-c786-ee7756f572d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "make_lyrics(\"If this is\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If this is your first time hearin this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSHshet40Mbo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}